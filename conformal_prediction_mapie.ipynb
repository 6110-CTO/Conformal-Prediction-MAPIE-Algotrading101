{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal Prediction - A Practical Guide with MAPIE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPIE Conformal Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mapie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPIE Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from mapie.classification import MapieClassifier\n",
    "from mapie.metrics import classification_coverage_score, classification_mean_width_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a toy dataset with two features and 3 classes (0, 1, 2) with a bit of noise\n",
    "\n",
    "n_samples = 1500\n",
    "n_features = 2\n",
    "n_classes = 3\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = np.zeros(n_samples)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    X[y == i] += np.random.randn(1, n_features) * 1.2\n",
    "\n",
    "y = np.where(X[:, 0] > 0, 0, 1)\n",
    "y = np.where(X[:, 1] > 0, y, y + 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train, X_cal, y_train, y_cal = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train a Gaussian Naive Bayes classifier\n",
    "\n",
    "clf = naive_bayes.GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training set\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(\n",
    "    X_train[:, 0],\n",
    "    X_train[:, 1],\n",
    "    c=y_train,\n",
    "    s=100,\n",
    "    cmap=\"viridis\",\n",
    "    edgecolor=\"k\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class labels and probabilities\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "# Calculate Softmax score\n",
    "softmax_score = np.max(y_pred_proba, axis=1)\n",
    "\n",
    "# Initialize the Conformal Prediction classifier\n",
    "mapie_score = MapieClassifier(estimator=clf, cv=\"prefit\", method=\"score\")\n",
    "mapie_score.fit(X_cal, y_cal)\n",
    "\n",
    "alpha = [0.2, 0.1, 0.05]\n",
    "y_pred_score, y_ps_score = mapie_score.predict(X_test, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from MAPIE docs\n",
    "def plot_scores(n, alphas, scores, quantiles):\n",
    "    colors = {0: \"#1f77b4\", 1: \"#ff7f0e\", 2: \"#2ca02c\"}\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.hist(scores, bins=\"auto\")\n",
    "    for i, quantile in enumerate(quantiles):\n",
    "        plt.vlines(\n",
    "            x=quantile,\n",
    "            ymin=0,\n",
    "            ymax=400,\n",
    "            color=colors[i],\n",
    "            ls=\"dashed\",\n",
    "            label=f\"alpha = {alphas[i]}\",\n",
    "        )\n",
    "    plt.title(\"Distribution of scores\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Scores\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of scores\n",
    "scores = mapie_score.conformity_scores_\n",
    "n = len(mapie_score.conformity_scores_)\n",
    "quantiles = mapie_score.quantiles_\n",
    "\n",
    "plot_scores(n, alpha, scores, quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken and adapted from MAPIE docs\n",
    "\n",
    "\n",
    "def plot_results(alphas, X, y_pred, y_ps):\n",
    "    tab10 = plt.cm.get_cmap(\"Purples\", 4)\n",
    "    colors = {0: \"#1f77b4\", 1: \"#ff7f0e\", 2: \"#2ca02c\", 3: \"#d62728\"}\n",
    "    y_pred_col = list(map(colors.get, y_pred))\n",
    "    fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axs = {0: ax1, 1: ax2, 2: ax3, 3: ax4}\n",
    "    axs[0].scatter(X[:, 0], X[:, 1], color=y_pred_col, marker=\".\", s=10, alpha=0.4)\n",
    "    axs[0].set_title(\"Predicted labels\")\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        y_pi_sums = y_ps[:, :, i].sum(axis=1)\n",
    "        num_labels = axs[i + 1].scatter(\n",
    "            X[:, 0],\n",
    "            X[:, 1],\n",
    "            c=y_pi_sums,\n",
    "            marker=\".\",\n",
    "            s=10,\n",
    "            alpha=1,\n",
    "            cmap=tab10,\n",
    "            vmin=0,\n",
    "            vmax=3,\n",
    "        )\n",
    "        plt.colorbar(num_labels, ax=axs[i + 1])\n",
    "        axs[i + 1].set_title(f\"Number of labels for alpha={alpha}\")\n",
    "\n",
    "    # color regions where the label wasn't predicted in red\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        y_pi_sums = y_ps[:, :, i].sum(axis=1)\n",
    "        axs[i + 1].scatter(\n",
    "            X[y_pi_sums == 0, 0],\n",
    "            X[y_pi_sums == 0, 1],\n",
    "            color=\"red\",\n",
    "            marker=\".\",\n",
    "            s=10,\n",
    "            alpha=0.4,\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_results(alpha, X_test, y_pred_score, y_ps_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha2 = np.arange(0.02, 0.98, 0.02)\n",
    "_, y_ps_score2 = mapie_score.predict(X_test, alpha=alpha2)\n",
    "coverages_score = [\n",
    "    classification_coverage_score(y_test, y_ps_score2[:, :, i])\n",
    "    for i, _ in enumerate(alpha2)\n",
    "]\n",
    "widths_score = [\n",
    "    classification_mean_width_score(y_ps_score2[:, :, i]) for i, _ in enumerate(alpha2)\n",
    "]\n",
    "\n",
    "\n",
    "def plot_coverages_widths(alpha, coverage, width, method):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axs[0].scatter(1 - alpha, coverage, label=method)\n",
    "    axs[0].set_xlabel(\"1 - alpha\")\n",
    "    axs[0].set_ylabel(\"Coverage score\")\n",
    "    axs[0].plot([0, 1], [0, 1], label=\"x=y\", color=\"black\")\n",
    "    axs[0].legend()\n",
    "    axs[1].scatter(1 - alpha, width, label=method)\n",
    "    axs[1].set_xlabel(\"1 - alpha\")\n",
    "    axs[1].set_ylabel(\"Average size of prediction sets\")\n",
    "    axs[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_coverages_widths(alpha2, coverages_score, widths_score, \"Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPIE Quantile Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.quantile_regression import MapieQuantileRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from mapie.metrics import regression_coverage_score, regression_mean_width_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the diamonds dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/diamonds.csv\"\n",
    ")\n",
    "\n",
    "# Create a train, calibration and test set\n",
    "X = df.drop([\"price\"], axis=1)\n",
    "# drop categorical variables for this example only\n",
    "X = X.drop([\"cut\", \"color\", \"clarity\"], axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_cal, X_test, y_cal, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of the target variable\n",
    "plt.hist(y_train, bins=\"auto\")\n",
    "plt.title(\"Distribution of prices\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from MAPIE docs\n",
    "\n",
    "\n",
    "def sort_y_values(y_test, y_pred, y_pis):\n",
    "    \"\"\"\n",
    "    Sorting the dataset in order to make plots using the fill_between function.\n",
    "    \"\"\"\n",
    "    indices = np.argsort(y_test)\n",
    "    y_test_sorted = np.array(y_test)[indices]\n",
    "    y_pred_sorted = y_pred[indices]\n",
    "    y_lower_bound = y_pis[:, 0, 0][indices]\n",
    "    y_upper_bound = y_pis[:, 1, 0][indices]\n",
    "    return y_test_sorted, y_pred_sorted, y_lower_bound, y_upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# fit a Quantile LightGBM model\n",
    "clf = LGBMRegressor(objective=\"quantile\", alpha=0.05, random_state=42)\n",
    "\n",
    "# optimize the model\n",
    "params_distributions = dict(\n",
    "    num_leaves=np.random.randint(10, 50, 5),\n",
    "    max_depth=np.random.randint(3, 20, 1),\n",
    "    n_estimators=np.random.randint(50, 300, 10),\n",
    "    learning_rate=np.random.uniform(0.01, 0.1, 10),\n",
    ")\n",
    "\n",
    "optim_model = RandomizedSearchCV(\n",
    "    clf,\n",
    "    param_distributions=params_distributions,\n",
    "    n_jobs=-1,\n",
    "    n_iter=100,\n",
    "    cv=KFold(n_splits=5, shuffle=True),\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "optim_model.fit(X_train, y_train)\n",
    "clf = optim_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapie = MapieQuantileRegressor(clf, method=\"quantile\", cv=\"split\", alpha=0.2)\n",
    "mapie.fit(X_train, y_train)\n",
    "\n",
    "# sort the data\n",
    "y_pred, y_pis = mapie.predict(X_test)\n",
    "\n",
    "(y_test_sorted, y_pred_sorted, lower_bound, upper_bound) = sort_y_values(\n",
    "    y_test, y_pred, y_pis\n",
    ")\n",
    "\n",
    "# Calculate the coverage and width of the prediction intervals\n",
    "coverage = regression_coverage_score(y_test, y_pis[:, 0, 0], y_pis[:, 1, 0])\n",
    "width = regression_mean_width_score(y_pis[:, 0, 0], y_pis[:, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  take 10% of the data to make the plot more readable\n",
    "y_test_sorted = y_test_sorted[2600:2800]\n",
    "y_pred_sorted = y_pred_sorted[2600:2800]\n",
    "lower_bound = lower_bound[2600:2800]\n",
    "upper_bound = upper_bound[2600:2800]\n",
    "\n",
    "# Prepare warnings when the prediction interval does not contain the true value\n",
    "error = y_pred_sorted - lower_bound\n",
    "warning1 = y_test_sorted > (y_pred_sorted + error)\n",
    "warning2 = y_test_sorted < (y_pred_sorted - error)\n",
    "warnings = warning1 + warning2\n",
    "\n",
    "plt.plot(y_test_sorted, y_test_sorted, label=\"True values\", color=\"black\")\n",
    "\n",
    "plt.errorbar(\n",
    "    y_test_sorted[~warnings],\n",
    "    y_pred_sorted[~warnings],\n",
    "    yerr=error[~warnings],\n",
    "    alpha=0.5,\n",
    "    fmt=\"o\",\n",
    "    color=\"blue\",\n",
    "    label=\"Inside Prediction interval\",\n",
    ")\n",
    "\n",
    "plt.errorbar(\n",
    "    y_test_sorted[warnings],\n",
    "    y_pred_sorted[warnings],\n",
    "    yerr=error[warnings],\n",
    "    fmt=\"o\",\n",
    "    color=\"red\",\n",
    "    ecolor=\"red\",\n",
    "    elinewidth=1,\n",
    "    capsize=2,\n",
    "    label=\"Prediction error\",\n",
    ")\n",
    "\n",
    "plt.title(f\"Prediction intervals with coverage {coverage:.2f} and width {width:.2f}\")\n",
    "plt.xlabel(\"True values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPIE Time Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.time_series_regression import MapieTimeSeriesRegressor\n",
    "from mapie.subsample import BlockBootstrap\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sales data\n",
    "df = pd.read_csv(\"sales.csv\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.set_index(\"date\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features\n",
    "df[\"month\"] = df.index.month\n",
    "df[\"year\"] = df.index.year\n",
    "\n",
    "# plot the data\n",
    "plt.plot(df[\"sales\"])\n",
    "plt.title(\"Sales\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test sets\n",
    "X = df.drop([\"sales\"], axis=1)\n",
    "y = df[\"sales\"]\n",
    "\n",
    "# split the data where test is eveyrthing after 1974\n",
    "X_train = X[X.index.year < 1974]\n",
    "X_test = X[X.index.year >= 1974]\n",
    "y_train = y[y.index.year < 1974]\n",
    "y_test = y[y.index.year >= 1974]\n",
    "\n",
    "# introduce a change in seasonality after 1975 in the y_test set by applying a 10% drop\n",
    "y_test.loc[y_test.index.year >= 1975] = y_test.loc[y_test.index.year >= 1975] * 0.9\n",
    "\n",
    "# plot the data whole data and colored train and test sets\n",
    "plt.plot(X_train.index, y_train, label=\"Train set\")\n",
    "plt.plot(X_test.index, y_test, label=\"Test set\")\n",
    "plt.title(\"Sales\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.XGBRegressor(n_estimators=1000, random_state=42)\n",
    "\n",
    "# optimize the model\n",
    "params_distributions = dict(\n",
    "    max_depth=np.random.randint(3, 20, 1),\n",
    "    learning_rate=np.random.uniform(0.01, 0.1, 10),\n",
    ")\n",
    "\n",
    "reg = RandomizedSearchCV(\n",
    "    reg,\n",
    "    param_distributions=params_distributions,\n",
    "    n_jobs=-1,\n",
    "    n_iter=10,\n",
    "    cv=KFold(n_splits=5, shuffle=True),\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's Confromal Prediction time!\n",
    "alpha = 0.05\n",
    "gap = 1\n",
    "\n",
    "mapie_cv = BlockBootstrap(n_blocks=10, overlapping=True, random_state=42)\n",
    "\n",
    "mapie_enbpi = MapieTimeSeriesRegressor(\n",
    "    reg, method=\"enbpi\", cv=mapie_cv, agg_function=\"mean\", n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapie_enbpi = mapie_enbpi.fit(X_train, y_train)\n",
    "y_pred_npfit, y_pis_npfit = mapie_enbpi.predict(\n",
    "    X_test, alpha=alpha, ensemble=True, optimize_beta=True\n",
    ")\n",
    "coverage_npfit = regression_coverage_score(\n",
    "    y_test, y_pis_npfit[:, 0, 0], y_pis_npfit[:, 1, 0]\n",
    ")\n",
    "width_npfit = regression_mean_width_score(y_pis_npfit[:, 0, 0], y_pis_npfit[:, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapie_enbpi = mapie_enbpi.fit(X_train, y_train)\n",
    "\n",
    "y_pred_pfit = np.zeros(y_pred_npfit.shape)\n",
    "y_pis_pfit = np.zeros(y_pis_npfit.shape)\n",
    "conformity_scores_pfit = []\n",
    "lower_quantiles_pfit = []\n",
    "higher_quantiles_pfit = []\n",
    "y_pred_pfit[:gap], y_pis_pfit[:gap, :, :] = mapie_enbpi.predict(\n",
    "    X_test.iloc[:gap, :], alpha=alpha, ensemble=True, optimize_beta=True\n",
    ")\n",
    "for step in range(gap, len(X_test), gap):\n",
    "    mapie_enbpi.partial_fit(\n",
    "        X_test.iloc[(step - gap) : step, :],\n",
    "        y_test.iloc[(step - gap) : step],\n",
    "    )\n",
    "    (\n",
    "        y_pred_pfit[step : step + gap],\n",
    "        y_pis_pfit[step : step + gap, :, :],\n",
    "    ) = mapie_enbpi.predict(\n",
    "        X_test.iloc[step : (step + gap), :],\n",
    "        alpha=alpha,\n",
    "        ensemble=True,\n",
    "        optimize_beta=True,\n",
    "    )\n",
    "    conformity_scores_pfit.append(mapie_enbpi.conformity_scores_)\n",
    "    lower_quantiles_pfit.append(mapie_enbpi.lower_quantiles_)\n",
    "    higher_quantiles_pfit.append(mapie_enbpi.higher_quantiles_)\n",
    "coverage_pfit = regression_coverage_score(\n",
    "    y_test, y_pis_pfit[:, 0, 0], y_pis_pfit[:, 1, 0]\n",
    ")\n",
    "width_pfit = regression_mean_width_score(y_pis_pfit[:, 0, 0], y_pis_pfit[:, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.plot(y_test.index, y_test, label=\"True values\")\n",
    "ax1.plot(y_test.index, y_pred_npfit, label=\"Predicted values\")\n",
    "ax1.fill_between(\n",
    "    y_test.index,\n",
    "    y_pis_npfit[:, 0, 0],\n",
    "    y_pis_npfit[:, 1, 0],\n",
    "    alpha=0.5,\n",
    "    label=\"Prediction intervals\",\n",
    ")\n",
    "ax1.set_title(\"Prediction intervals for non partial fit\")\n",
    "ax1.text(\n",
    "    0.5,\n",
    "    0.9,\n",
    "    f\"Coverage: {round(coverage_npfit,2 )} \\nWidth: {round(width_npfit,2)}\",\n",
    "    horizontalalignment=\"center\",\n",
    "    verticalalignment=\"center\",\n",
    "    transform=ax1.transAxes,\n",
    ")\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Sales\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(y_test.index, y_test, label=\"True values\")\n",
    "ax2.plot(y_test.index, y_pred_pfit, label=\"Predicted values\")\n",
    "ax2.fill_between(\n",
    "    y_test.index,\n",
    "    y_pis_pfit[:, 0, 0],\n",
    "    y_pis_pfit[:, 1, 0],\n",
    "    alpha=0.5,\n",
    "    label=\"Prediction intervals\",\n",
    ")\n",
    "ax2.set_title(\"Prediction intervals for partial fit\")\n",
    "ax2.text(\n",
    "    0.5,\n",
    "    0.9,\n",
    "    f\"Coverage: {round(coverage_pfit,2)} \\nWidth: {round(width_pfit, 2)}\",\n",
    "    horizontalalignment=\"center\",\n",
    "    verticalalignment=\"center\",\n",
    "    transform=ax2.transAxes,\n",
    ")\n",
    "ax2.set_xlabel(\"Date\")\n",
    "ax2.set_ylabel(\"Sales\")\n",
    "ax2.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mu_production')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb1ca64d0833c17358fac97fe4558bb2b7364b384a8303d0529bb930f363e141"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
